Thu Apr 10 13:08:25 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.86.15              Driver Version: 570.86.15      CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-80GB          Off |   00000000:4C:00.0 Off |                    0 |
| N/A   36C    P0             61W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
[NeMo I 2025-04-10 13:09:27 mixins:196] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2025-04-10 13:09:29 mixins:330] Tokenizer SentencePieceTokenizer initialized with 32 tokens
[NeMo I 2025-04-10 13:09:29 mixins:330] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2025-04-10 13:09:29 mixins:330] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2025-04-10 13:09:29 mixins:330] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2025-04-10 13:09:29 mixins:330] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2025-04-10 13:09:29 aggregate_tokenizer:72] Aggregate vocab size: 4128
[NeMo W 2025-04-10 13:09:29 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    tarred_audio_filepaths: null
    manifest_filepath: null
    sample_rate: 16000
    shuffle: true
    batch_size: null
    num_workers: 8
    use_lhotse: true
    max_duration: 40
    pin_memory: true
    use_bucketing: false
    bucket_duration_bins: null
    num_buckets: 1
    text_field: answer
    lang_field: target_lang
    batch_duration: 360
    quadratic_duration: 15
    bucket_buffer_size: 20000
    shuffle_buffer_size: 10000
    
[NeMo W 2025-04-10 13:09:29 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 8
    shuffle: false
    num_workers: 0
    pin_memory: true
    tarred_audio_filepaths: null
    use_lhotse: true
    text_field: answer
    lang_field: target_lang
    use_bucketing: false
    
[NeMo W 2025-04-10 13:09:29 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 0
    pin_memory: true
    tarred_audio_filepaths: null
    use_lhotse: true
    text_field: answer
    lang_field: target_lang
    use_bucketing: false
    
[NeMo I 2025-04-10 13:09:29 features:289] PADDING: 0
[NeMo W 2025-04-10 13:09:38 nemo_logging:349] /home/chaseez/.conda/envs/asl-segmentation/lib/python3.10/site-packages/nemo/core/connectors/save_restore_connector.py:571: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
      return torch.load(model_weights, map_location='cpu')
    
[NeMo I 2025-04-10 13:09:41 save_restore_connector:249] Model EncDecMultiTaskModel was successfully restored from /home/chaseez/.cache/huggingface/hub/models--nvidia--canary-1b/snapshots/51d6c4d5d4c20250a1f06f3b83e50241cfabca35/canary-1b.nemo.
8
